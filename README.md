# 강의
- Inflearn > 스프링부트로 직접 만들면서 배우는 대규모 시스템 설계(캐시 전략)

## 프로젝트 설정
### 타이틀
- 내용


## 개념정리
### 캐시
- 캐시란?
  - 더욱 빠른 저장소에 데이터를 보관하여, 해당 데이터에 빠르게 접근하는 기술
- 이점
  - 데이터 접근 속도 향상 
  - 저장소 부하 분산
    - ex. 레디스 같은 캐시를 사용하여 DB의 접근을 줄인다면, 부하가 분산되는 효과를 가져올 수 있다.
- Slow Storage와 Fast Storage
  - 데이터를 조회하기 위해서 대부분 Slow Storage에 접근한다.
    - 하지만 접근비용이 크고, 속도가 느리다.
    - 이를 해결하기 위해서 Slow Storage의 데이터를 Fast Storage에 캐시할 수 있다.
  - 모든 데이터를 Fast Storage에 저장하면 안되는가?
    - Fast Storage는 빠르지만 비싸다.
    - Slow Storage에 비해 안정성이 떨어진다.
    - 때문에 모든 데이터를 Fast Storage에 저장할 수는 없다.
    - 또한 파레토 법칙에 의하면, 모든 데이터를 Fast Storage에 저장할 필요도 없다.
      - 파레토 법칙
        - 전체 결과의 80%가 전체 원인의 20%에서 일어나는 현상
          - 전체 조회 트래픽의 대부분(약 80%)은 소수의 데이터(약 20%)에 집중된다. 
          - 자주 조회되는 핵심 데이터가 반복해서 읽힌다.
        - 따라서 일부 데이터만 캐시해도 효율적으로 동작한다.
- 캐시의 종류
  - Local Cache
    - 각 서버 애플리케이션 내부 메모리에 캐시
    - 매우 빠름
    - 서버 메모리 부담, 재시작 시 휘발, 데이터 일관성 관리 어려움(서버 애플리케이션 간 동기화 문제)
    - 대표 라이브러리 : Caffeine, Ehcache 등
  - Remote Cache(Global Cache)
    - 별도 서버 메모리에 캐시
    - 네트워크 통한 접근 필요하므로 Local Cache 보다 느림
    - 별도 서버 메모리에 저장하기 때문에 Local Cache 보다 큰 데이터를 장기간 저장할 수 있음
    - 여러 서버 애플리케이션이 동일한 저장소에 접근하므로 데이터 일관성 관리 유리
    - 대표 솔루션 : Redis, Memcached 등 인메모리 데이터베이스 및 라이브러리
